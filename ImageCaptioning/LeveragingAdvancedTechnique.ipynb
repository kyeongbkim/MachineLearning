{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64f6d5d-db3f-4bbd-a772-10cf253342a8",
   "metadata": {},
   "source": [
    "This image captioning project is dealing with both images and texts at the same time, which means advanced technologies in both areas are leveraged. Here's the list of techniques used in this project:\n",
    "\n",
    "* VGG-16: Rather than training the model from the scratch, pre-trained models can be used as the starting point. In my project, VGG-16 model was used which is a convolutional neural network that is 16 layers deep and processing input size of 224x224. By leverating this model, I was able to achive reasonable performance without spending too much time on feature extraction.\n",
    "\n",
    "* FastText: I brought wiki-news-300d-1M.vec which was trained on 1 million word vectors trained with subword infomation on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens). In this embedding data, each word is represented in 300-dimension feature vectors with similar meaning to have a similar representation.\n",
    "\n",
    "* NLTK: NLTK is a leading platform for building Python programs to work with human language data. I used this tool for text preprocessing(word tokenization, etc) and performance evaluation(BLEU, METEOR score).\n",
    "\n",
    "* LSTM and GRU: RNN(Recurrent Neural Network)'s are good for processing sequence data for predictions but suffers from short-term memory. LSTM(Long short term memory and GRU(Gated Recurrent Units) overcome this short-comings. I used LSTM for two models(cascade, merge) and GRU for one model(attention).\n",
    "\n",
    "* Transformer: A transformer is a deep learning model that adopts the mechanism of self-attention. It was designed to process sequential input data and has shown excellent performance in areas such as machine translation and document summarization. I tried to apply that to image captioning and the result was best among three "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f468ecd-6aa9-45ed-8871-457244bbee24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MEC Mini-Projects)",
   "language": "python",
   "name": "mec-miniprojects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
